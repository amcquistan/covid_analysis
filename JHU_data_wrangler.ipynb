{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### John Hopkins GitHub Repo Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import uuid\n",
    "from slugify import slugify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__name__))), 'COVID-19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the confirmed cases time series files in here have Lat and Long for each location\n",
    "# confirmed_series_file = os.path.join(\n",
    "#     DATA_DIR,\n",
    "#     'csse_covid_19_data',\n",
    "#     'csse_covid_19_time_series',\n",
    "#     'time_series_covid19_confirmed_global.csv'\n",
    "# )\n",
    "# confirmed_series_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 10 rows of time_series_19-covid-Confirmed.csv file\n",
    "#!awk -F, '{print $1,$2,$3,$4} NR==10{exit}' OFS=', ' \\\n",
    "# COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols=['Province/State', 'Country/Region', 'Lat', 'Long']\n",
    "# locations_df = pd.read_csv(confirmed_series_file, usecols=cols)\n",
    "# locations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = boto3.resource('s3')\n",
    "bucket_name = 'thecodinginterface-covid'\n",
    "s3_bucket = s3_resource.Bucket(name=bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slugify_location(country_region, province_state):\n",
    "    if province_state:\n",
    "        return slugify(f\"{country_region}-{province_state}\")\n",
    "    return slugify(country_region)\n",
    "\n",
    "def cloud_resource_url(filename, bucket_name):\n",
    "    return f\"https://{bucket_name}.s3.amazonaws.com/{filename}.json\"\n",
    "\n",
    "def upload_file_to_s3(s3_bucket, file_path, file_name):\n",
    "    s3_bucket.upload_file(\n",
    "        Filename=file_path,\n",
    "        Key=file_name,\n",
    "        ExtraArgs={'ACL':'public-read'}\n",
    "    )\n",
    "    return cloud_resource_url(file_name, s3_bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be snake_cased making it more ammenable to serialization\n",
    "# locations_df = locations_df.rename(columns={\n",
    "#     'Province/State': 'province_state',\n",
    "#     'Country/Region': 'country_region',\n",
    "#     'Lat': 'lat',\n",
    "#     'Long': 'long'\n",
    "# })\n",
    "\n",
    "# # make sure text columns are well cleaned and stripped of whitespace\n",
    "# locations_df.province_state = locations_df.province_state.str.strip()\n",
    "# locations_df.country_region = locations_df.country_region.str.strip()\n",
    "\n",
    "# # Fill NaNs with empty strings in the Province/State columns because this data will\n",
    "# # be serialized into JSON which does not support NaN\n",
    "# locations_df.province_state = locations_df.province_state.fillna('')\n",
    "\n",
    "# # create columns \"filename\" and \"cloud_resource\"\n",
    "# lookup_keys = zip(locations_df.country_region, locations_df.province_state)\n",
    "# locations_df['location_id'] = [slugify_location(country_region, province_state)\n",
    "#                             for country_region, province_state in lookup_keys]\n",
    "\n",
    "# locations_df['cloud_resource'] = [cloud_resource_url(filename, bucket_name)\n",
    "#                                   for filename in locations_df['location_id'].values]\n",
    "\n",
    "# locations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations_df.country_region.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations_df = locations_df.set_index('location_id')\n",
    "# locations_df[locations_df.country_region == 'US'].sort_values('province_state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll do more with this locations_df DataFrame later after\n",
    "# constructing country specific case data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02-26-2020.csv',\n",
       " '02-27-2020.csv',\n",
       " '02-18-2020.csv',\n",
       " '02-19-2020.csv',\n",
       " '03-24-2020.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build list of daily csv files\n",
    "daily_series_dir = os.path.join(\n",
    "    DATA_DIR,\n",
    "    'csse_covid_19_data',\n",
    "    'csse_covid_19_daily_reports'\n",
    ")\n",
    "daily_csv_files = [file_name\n",
    "                   for file_name in os.listdir(daily_series_dir) \n",
    "                   if file_name.endswith('csv')]\n",
    "daily_csv_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/adammcquistan/Code/python/COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/03-08-2020.csv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a peek at the structure of a file that will be worked with\n",
    "os.path.join(daily_series_dir, daily_csv_files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head ./COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/02-26-2020.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_differential(x):\n",
    "    x0 = np.array([0] + x[:-1].tolist())\n",
    "    dx = x.values - x0\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>total_confirmed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>total_recovered</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Algeria</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From Diamond Princess</td>\n",
       "      <td>Australia</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Queensland</td>\n",
       "      <td>Australia</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Victoria</td>\n",
       "      <td>Australia</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>Austria</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          province_state country_region  total_confirmed  total_deaths  \\\n",
       "0                           Afghanistan              1.0           0.0   \n",
       "1                               Algeria              1.0           0.0   \n",
       "2  From Diamond Princess      Australia              7.0           0.0   \n",
       "3        New South Wales      Australia              4.0           0.0   \n",
       "4             Queensland      Australia              5.0           0.0   \n",
       "5        South Australia      Australia              2.0           0.0   \n",
       "6               Victoria      Australia              4.0           0.0   \n",
       "7                               Austria              2.0           0.0   \n",
       "8                               Bahrain             33.0           0.0   \n",
       "9                               Belgium              1.0           0.0   \n",
       "\n",
       "   total_recovered       date  \n",
       "0              0.0 2020-02-26  \n",
       "1              0.0 2020-02-26  \n",
       "2              0.0 2020-02-26  \n",
       "3              4.0 2020-02-26  \n",
       "4              1.0 2020-02-26  \n",
       "5              2.0 2020-02-26  \n",
       "6              4.0 2020-02-26  \n",
       "7              0.0 2020-02-26  \n",
       "8              0.0 2020-02-26  \n",
       "9              1.0 2020-02-26  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the daily files into DataFrame objects then concatenate them together\n",
    "daily_dfs = []\n",
    "colunns_of_interest = [\n",
    "    'province_state',\n",
    "    'country_region',\n",
    "    'total_confirmed',\n",
    "    'total_deaths',\n",
    "    'total_recovered',\n",
    "    'date'\n",
    "]\n",
    "\n",
    "for file_name in daily_csv_files:\n",
    "    file_path = os.path.join(daily_series_dir, file_name)\n",
    "    day_df = pd.read_csv(file_path)\n",
    "\n",
    "    # Province_State and Country_Region replaced column names Province/State\n",
    "    # and Country/Region for new daily files starting 03-24-2020\n",
    "    day_df = day_df.rename(columns={\n",
    "            'Province/State': 'province_state',\n",
    "            'Province_State': 'province_state', \n",
    "            'Country/Region': 'country_region',\n",
    "            'Country_Region': 'country_region',\n",
    "            'Confirmed': 'total_confirmed',\n",
    "            'Deaths':'total_deaths',\n",
    "            'Recovered': 'total_recovered'\n",
    "        })\n",
    "    \n",
    "    date_str, ext = os.path.splitext(file_name)\n",
    "    num_rows = day_df.shape[0]\n",
    "    day_df['date'] = [pd.to_datetime(date_str)] * num_rows\n",
    "\n",
    "    # Fill NaNs with empty strings because this data will\n",
    "    # be serialized into JSON which does not support NaN\n",
    "    day_df.province_state = day_df.province_state.fillna('')\n",
    "    day_df.total_confirmed = day_df.total_confirmed.fillna(0)\n",
    "    day_df.total_deaths = day_df.total_deaths.fillna(0)\n",
    "    day_df.total_recovered = day_df.total_recovered.fillna(0)\n",
    "\n",
    "    missing_columns = sum([(col not in day_df.columns) for col in colunns_of_interest])\n",
    "    if missing_columns:\n",
    "        import pdb; pdb.set_trace()\n",
    "        sys.exit(0)\n",
    "\n",
    "    whole_country_df = day_df[colunns_of_interest].groupby(['country_region']).sum()\n",
    "    whole_country_df = whole_country_df.reset_index()\n",
    "    whole_country_df['province_state'] = [''] * whole_country_df.shape[0]\n",
    "        \n",
    "    if 'Admin2' in day_df.columns:\n",
    "        county_df = day_df[day_df.Admin2 != '']\n",
    "        county_df['province_state'] = county_df.Admin2 + ', ' + county_df.province_state\n",
    "        day_df = pd.concat([day_df[colunns_of_interest], county_df[colunns_of_interest], whole_country_df])\n",
    "    else:\n",
    "        day_df = pd.concat([day_df[colunns_of_interest], whole_country_df])\n",
    "    \n",
    "#     day_df = day_df[colunns_of_interest]\n",
    "    \n",
    "    # increased granularity by neighborhood was added in Admin2 column 03-24-2020\n",
    "    # but only want granularity down to province_region so collapse down and aggregate\n",
    "    day_df = day_df.groupby(['country_region', 'province_state', 'date']).sum()\n",
    "    day_df = day_df.reset_index()\n",
    "    \n",
    "    daily_dfs.append(day_df[colunns_of_interest])\n",
    "    \n",
    "daily_df = pd.concat(daily_dfs)\n",
    "# make sure text columns are well cleaned and stripped of whitespace\n",
    "daily_df.province_state = daily_df.province_state.str.strip()\n",
    "daily_df.country_region = daily_df.country_region.str.strip()\n",
    "daily_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole_country_df = daily_df.groupby(['country_region', 'date']).sum()\n",
    "# whole_country_df = whole_country_df.reset_index()\n",
    "# whole_country_df['province_state'] = [''] * whole_country_df.shape[0]\n",
    "# whole_country_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>total_confirmed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>total_recovered</th>\n",
       "      <th>date</th>\n",
       "      <th>location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>421.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>525.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>732.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>967.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>2495.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>5365.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>8310.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>11710.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>15800.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>20884.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>25681.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>30841.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>37877.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>44876.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>52410.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>59648.0</td>\n",
       "      <td>965.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>66663.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>75833.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>83948.0</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>92506.0</td>\n",
       "      <td>2373.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>102987.0</td>\n",
       "      <td>2935.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>113833.0</td>\n",
       "      <td>3565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     province_state country_region  total_confirmed  total_deaths  \\\n",
       "183        New York             US            173.0           0.0   \n",
       "190        New York             US            220.0           0.0   \n",
       "192        New York             US            328.0           0.0   \n",
       "205        New York             US            421.0           0.0   \n",
       "219        New York             US            525.0           2.0   \n",
       "227        New York             US            732.0           3.0   \n",
       "240        New York             US            967.0          10.0   \n",
       "244        New York             US           1706.0          13.0   \n",
       "249        New York             US           2495.0          16.0   \n",
       "256        New York             US           5365.0          34.0   \n",
       "262        New York             US           8310.0          42.0   \n",
       "266        New York             US          11710.0          60.0   \n",
       "2329       New York             US          15800.0         117.0   \n",
       "2323       New York             US          20884.0         158.0   \n",
       "2326       New York             US          25681.0         210.0   \n",
       "2330       New York             US          30841.0         285.0   \n",
       "2332       New York             US          37877.0         385.0   \n",
       "2333       New York             US          44876.0         527.0   \n",
       "2334       New York             US          52410.0         728.0   \n",
       "2334       New York             US          59648.0         965.0   \n",
       "2335       New York             US          66663.0        1218.0   \n",
       "1667       New York             US          75833.0        1550.0   \n",
       "1706       New York             US          83948.0        1941.0   \n",
       "1762       New York             US          92506.0        2373.0   \n",
       "1793       New York             US         102987.0        2935.0   \n",
       "1831       New York             US         113833.0        3565.0   \n",
       "\n",
       "      total_recovered       date  location_id  \n",
       "183               0.0 2020-03-10  us-new-york  \n",
       "190               0.0 2020-03-11  us-new-york  \n",
       "192               0.0 2020-03-12  us-new-york  \n",
       "205               0.0 2020-03-13  us-new-york  \n",
       "219               0.0 2020-03-14  us-new-york  \n",
       "227               0.0 2020-03-15  us-new-york  \n",
       "240               0.0 2020-03-16  us-new-york  \n",
       "244               0.0 2020-03-17  us-new-york  \n",
       "249               0.0 2020-03-18  us-new-york  \n",
       "256               0.0 2020-03-19  us-new-york  \n",
       "262               0.0 2020-03-20  us-new-york  \n",
       "266               0.0 2020-03-21  us-new-york  \n",
       "2329              0.0 2020-03-22  us-new-york  \n",
       "2323              0.0 2020-03-23  us-new-york  \n",
       "2326              0.0 2020-03-24  us-new-york  \n",
       "2330              0.0 2020-03-25  us-new-york  \n",
       "2332              0.0 2020-03-26  us-new-york  \n",
       "2333              0.0 2020-03-27  us-new-york  \n",
       "2334              0.0 2020-03-28  us-new-york  \n",
       "2334              0.0 2020-03-29  us-new-york  \n",
       "2335              0.0 2020-03-30  us-new-york  \n",
       "1667              0.0 2020-03-31  us-new-york  \n",
       "1706              0.0 2020-04-01  us-new-york  \n",
       "1762              0.0 2020-04-02  us-new-york  \n",
       "1793              0.0 2020-04-03  us-new-york  \n",
       "1831              0.0 2020-04-04  us-new-york  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# daily_df = pd.concat([daily_df, whole_country_df])\n",
    "daily_df = daily_df.drop_duplicates()\n",
    "locations = zip(daily_df.country_region.values, daily_df.province_state.values)\n",
    "daily_df['location_id'] = [slugify_location(country_region, province_state)\n",
    "                           for country_region, province_state in locations]\n",
    "\n",
    "# sort by country_region, province_state, date\n",
    "daily_df = daily_df.sort_values(['country_region', 'province_state', 'date'])\n",
    "daily_df[(daily_df.country_region == 'US') & (daily_df.province_state == 'New York')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_confirmed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>total_recovered</th>\n",
       "      <th>death_rate</th>\n",
       "      <th>recovery_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spain</th>\n",
       "      <td>126168.0</td>\n",
       "      <td>11947.0</td>\n",
       "      <td>34219.0</td>\n",
       "      <td>9.469121</td>\n",
       "      <td>27.121774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>italy</th>\n",
       "      <td>124632.0</td>\n",
       "      <td>15362.0</td>\n",
       "      <td>20996.0</td>\n",
       "      <td>12.325887</td>\n",
       "      <td>16.846396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us-new-york</th>\n",
       "      <td>113833.0</td>\n",
       "      <td>3565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.131781</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>germany</th>\n",
       "      <td>96092.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>26400.0</td>\n",
       "      <td>1.502727</td>\n",
       "      <td>27.473671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>france</th>\n",
       "      <td>89953.0</td>\n",
       "      <td>7560.0</td>\n",
       "      <td>15438.0</td>\n",
       "      <td>8.404389</td>\n",
       "      <td>17.162296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>china-hubei</th>\n",
       "      <td>67803.0</td>\n",
       "      <td>3207.0</td>\n",
       "      <td>63762.0</td>\n",
       "      <td>4.729879</td>\n",
       "      <td>94.040087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us-new-york-city-new-york</th>\n",
       "      <td>63306.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.009193</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iran</th>\n",
       "      <td>55743.0</td>\n",
       "      <td>3452.0</td>\n",
       "      <td>19736.0</td>\n",
       "      <td>6.192706</td>\n",
       "      <td>35.405342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united-kingdom</th>\n",
       "      <td>41903.0</td>\n",
       "      <td>4313.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>10.292819</td>\n",
       "      <td>0.322173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us-new-jersey</th>\n",
       "      <td>34124.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.479194</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           total_confirmed  total_deaths  total_recovered  \\\n",
       "location_id                                                                 \n",
       "spain                             126168.0       11947.0          34219.0   \n",
       "italy                             124632.0       15362.0          20996.0   \n",
       "us-new-york                       113833.0        3565.0              0.0   \n",
       "germany                            96092.0        1444.0          26400.0   \n",
       "france                             89953.0        7560.0          15438.0   \n",
       "china-hubei                        67803.0        3207.0          63762.0   \n",
       "us-new-york-city-new-york          63306.0        1905.0              0.0   \n",
       "iran                               55743.0        3452.0          19736.0   \n",
       "united-kingdom                     41903.0        4313.0            135.0   \n",
       "us-new-jersey                      34124.0         846.0              0.0   \n",
       "\n",
       "                           death_rate  recovery_rate  \n",
       "location_id                                           \n",
       "spain                        9.469121      27.121774  \n",
       "italy                       12.325887      16.846396  \n",
       "us-new-york                  3.131781       0.000000  \n",
       "germany                      1.502727      27.473671  \n",
       "france                       8.404389      17.162296  \n",
       "china-hubei                  4.729879      94.040087  \n",
       "us-new-york-city-new-york    3.009193       0.000000  \n",
       "iran                         6.192706      35.405342  \n",
       "united-kingdom              10.292819       0.322173  \n",
       "us-new-jersey                2.479194       0.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get totals per location\n",
    "max_date = daily_df.date.max()\n",
    "rows_of_interest = daily_df.date == max_date\n",
    "columns_of_interest = [\n",
    "    'location_id',\n",
    "    'total_confirmed',\n",
    "    'total_deaths',\n",
    "    'total_recovered'\n",
    "]\n",
    "location_totals_df = daily_df.loc[rows_of_interest, columns_of_interest]\n",
    "location_totals_df = location_totals_df.groupby('location_id').sum()\n",
    "location_totals_df['death_rate'] = location_totals_df.total_deaths / location_totals_df.total_confirmed * 100\n",
    "location_totals_df['recovery_rate'] = location_totals_df.total_recovered / location_totals_df.total_confirmed * 100\n",
    "location_totals_df.sort_values('total_confirmed', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get totals per country / region\n",
    "# country_totals_df = locations_df.join(location_totals_df)\n",
    "# columns_of_interest = [\n",
    "#     'country_region',\n",
    "#     'total_confirmed',\n",
    "#     'total_deaths',\n",
    "#     'total_recovered',\n",
    "# ]\n",
    "# country_totals_df = country_totals_df.reset_index()\n",
    "# country_totals_df = country_totals_df[columns_of_interest].groupby('country_region').sum()\n",
    "# country_totals_df['death_rate'] = country_totals_df.total_deaths / country_totals_df.total_confirmed * 100\n",
    "# country_totals_df['recovery_rate'] = country_totals_df.total_recovered / country_totals_df.total_confirmed * 100\n",
    "# country_totals_df.sort_values('country_region').head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# world_population_df = pd.read_csv('world_population.csv')\n",
    "# world_population_df = world_population_df.set_index('country_region')\n",
    "# world_population_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add population data to country totals\n",
    "# country_totals_df = country_totals_df.join(world_population_df)\n",
    "# country_totals_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>total_confirmed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>total_recovered</th>\n",
       "      <th>date</th>\n",
       "      <th>location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>9654.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>12305.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>14904.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>17856.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>21873.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>25573.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>29776.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>33768.0</td>\n",
       "      <td>678.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>37453.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>43119.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>47439.0</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>51809.0</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>57159.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>63306.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               province_state country_region  total_confirmed  total_deaths  \\\n",
       "2330  New York City, New York             US           9654.0          63.0   \n",
       "2324  New York City, New York             US          12305.0          99.0   \n",
       "2327  New York City, New York             US          14904.0         131.0   \n",
       "2331  New York City, New York             US          17856.0         199.0   \n",
       "2333  New York City, New York             US          21873.0         281.0   \n",
       "2334  New York City, New York             US          25573.0         366.0   \n",
       "2335  New York City, New York             US          29776.0         517.0   \n",
       "2335  New York City, New York             US          33768.0         678.0   \n",
       "2336  New York City, New York             US          37453.0         790.0   \n",
       "1668  New York City, New York             US          43119.0         932.0   \n",
       "1707  New York City, New York             US          47439.0        1139.0   \n",
       "1763  New York City, New York             US          51809.0        1397.0   \n",
       "1794  New York City, New York             US          57159.0        1584.0   \n",
       "1832  New York City, New York             US          63306.0        1905.0   \n",
       "\n",
       "      total_recovered       date                location_id  \n",
       "2330              0.0 2020-03-22  us-new-york-city-new-york  \n",
       "2324              0.0 2020-03-23  us-new-york-city-new-york  \n",
       "2327              0.0 2020-03-24  us-new-york-city-new-york  \n",
       "2331              0.0 2020-03-25  us-new-york-city-new-york  \n",
       "2333              0.0 2020-03-26  us-new-york-city-new-york  \n",
       "2334              0.0 2020-03-27  us-new-york-city-new-york  \n",
       "2335              0.0 2020-03-28  us-new-york-city-new-york  \n",
       "2335              0.0 2020-03-29  us-new-york-city-new-york  \n",
       "2336              0.0 2020-03-30  us-new-york-city-new-york  \n",
       "1668              0.0 2020-03-31  us-new-york-city-new-york  \n",
       "1707              0.0 2020-04-01  us-new-york-city-new-york  \n",
       "1763              0.0 2020-04-02  us-new-york-city-new-york  \n",
       "1794              0.0 2020-04-03  us-new-york-city-new-york  \n",
       "1832              0.0 2020-04-04  us-new-york-city-new-york  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_df[(daily_df.country_region == 'US') & (daily_df.location_id == 'us-new-york-city-new-york')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by location and serialize each location dataset to a json file\n",
    "# [ \n",
    "#   {\n",
    "#     date: str,\n",
    "#     province_state: str,\n",
    "#     confirmed: int,\n",
    "#     deaths: int,\n",
    "#     recovered: int\n",
    "#   }, ...\n",
    "# ]\n",
    "\n",
    "location_case_data = 'location_case_data'\n",
    "if not os.path.exists(location_case_data):\n",
    "    os.mkdir(location_case_data)\n",
    "\n",
    "location_groups = daily_df.groupby(['location_id'])\n",
    "for location_id, location_data in location_groups:\n",
    "    location_data = location_data.sort_values('date')\n",
    "    location_data.loc[:,'daily_confirmed'] = calc_differential(location_data.total_confirmed)\n",
    "    location_data.loc[:,'daily_deaths'] = calc_differential(location_data.total_deaths)\n",
    "    location_data.loc[:,'daily_recovered'] = calc_differential(location_data.total_recovered)\n",
    "    \n",
    "    location_days = []\n",
    "\n",
    "    for idx, row in location_data.iterrows():\n",
    "        data = row.to_dict()\n",
    "        # dates don't serialize well in Python so, convert to strings\n",
    "        data['date'] = data['date'].strftime('%Y-%m-%d')\n",
    "        location_days.append(data)\n",
    "\n",
    "    filename = f\"{location_id}.json\"\n",
    "    file_path = os.path.join(location_case_data, filename)\n",
    "\n",
    "    with open(file_path, 'w') as fo:\n",
    "        json.dump(location_days, fo, indent=4)\n",
    "\n",
    "    s3_url = upload_file_to_s3(s3_bucket, file_path, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations_df.head(25)\n",
    "# locations_df = locations_df.reset_index()\n",
    "# locations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>cloud_resource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td></td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>https://thecodinginterface-covid.s3.amazonaws....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>albania</td>\n",
       "      <td></td>\n",
       "      <td>Albania</td>\n",
       "      <td>https://thecodinginterface-covid.s3.amazonaws....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>algeria</td>\n",
       "      <td></td>\n",
       "      <td>Algeria</td>\n",
       "      <td>https://thecodinginterface-covid.s3.amazonaws....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andorra</td>\n",
       "      <td></td>\n",
       "      <td>Andorra</td>\n",
       "      <td>https://thecodinginterface-covid.s3.amazonaws....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angola</td>\n",
       "      <td></td>\n",
       "      <td>Angola</td>\n",
       "      <td>https://thecodinginterface-covid.s3.amazonaws....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location_id province_state country_region  \\\n",
       "0  afghanistan                   Afghanistan   \n",
       "1      albania                       Albania   \n",
       "1      algeria                       Algeria   \n",
       "2      andorra                       Andorra   \n",
       "4       angola                        Angola   \n",
       "\n",
       "                                      cloud_resource  \n",
       "0  https://thecodinginterface-covid.s3.amazonaws....  \n",
       "1  https://thecodinginterface-covid.s3.amazonaws....  \n",
       "1  https://thecodinginterface-covid.s3.amazonaws....  \n",
       "2  https://thecodinginterface-covid.s3.amazonaws....  \n",
       "4  https://thecodinginterface-covid.s3.amazonaws....  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_df = daily_df[['location_id', 'province_state', 'country_region']].drop_duplicates()\n",
    "locations_df['cloud_resource'] = [cloud_resource_url(location_id, bucket_name) \n",
    "                                  for location_id in locations_df.location_id.values]\n",
    "locations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>cloud_resource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>us-nebraska</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>US</td>\n",
       "      <td>https://thecodinginterface-covid.s3.amazonaws....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     location_id province_state country_region  \\\n",
       "178  us-nebraska       Nebraska             US   \n",
       "\n",
       "                                        cloud_resource  \n",
       "178  https://thecodinginterface-covid.s3.amazonaws....  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_df[locations_df.province_state == 'Nebraska']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location_id': 'afghanistan', 'province_state': '', 'country_region': 'Afghanistan', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/afghanistan.json'}\n",
      "{'location_id': 'albania', 'province_state': '', 'country_region': 'Albania', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/albania.json'}\n",
      "{'location_id': 'algeria', 'province_state': '', 'country_region': 'Algeria', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/algeria.json'}\n",
      "{'location_id': 'andorra', 'province_state': '', 'country_region': 'Andorra', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/andorra.json'}\n",
      "{'location_id': 'angola', 'province_state': '', 'country_region': 'Angola', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/angola.json'}\n",
      "{'location_id': 'antigua-and-barbuda', 'province_state': '', 'country_region': 'Antigua and Barbuda', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/antigua-and-barbuda.json'}\n",
      "{'location_id': 'argentina', 'province_state': '', 'country_region': 'Argentina', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/argentina.json'}\n",
      "{'location_id': 'armenia', 'province_state': '', 'country_region': 'Armenia', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/armenia.json'}\n",
      "{'location_id': 'australia', 'province_state': '', 'country_region': 'Australia', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/australia.json'}\n",
      "{'location_id': 'australia-from-diamond-princess', 'province_state': 'From Diamond Princess', 'country_region': 'Australia', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/australia-from-diamond-princess.json'}\n",
      "{'location_id': 'australia-new-south-wales', 'province_state': 'New South Wales', 'country_region': 'Australia', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/australia-new-south-wales.json'}\n",
      "{'location_id': 'australia-queensland', 'province_state': 'Queensland', 'country_region': 'Australia', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/australia-queensland.json'}\n",
      "{'location_id': 'australia-south-australia', 'province_state': 'South Australia', 'country_region': 'Australia', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/australia-south-australia.json'}\n",
      "{'location_id': 'australia-victoria', 'province_state': 'Victoria', 'country_region': 'Australia', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/australia-victoria.json'}\n",
      "{'location_id': 'azerbaijan', 'province_state': '', 'country_region': 'Azerbaijan', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/azerbaijan.json'}\n",
      "{'location_id': 'belgium', 'province_state': '', 'country_region': 'Belgium', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/belgium.json'}\n",
      "{'location_id': 'brazil', 'province_state': '', 'country_region': 'Brazil', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/brazil.json'}\n",
      "{'location_id': 'cambodia', 'province_state': '', 'country_region': 'Cambodia', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/cambodia.json'}\n",
      "{'location_id': 'canada-british-columbia', 'province_state': 'British Columbia', 'country_region': 'Canada', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/canada-british-columbia.json'}\n",
      "{'location_id': 'canada-ontario', 'province_state': 'Ontario', 'country_region': 'Canada', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/canada-ontario.json'}\n",
      "{'location_id': 'colombia', 'province_state': '', 'country_region': 'Colombia', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/colombia.json'}\n",
      "{'location_id': 'france', 'province_state': '', 'country_region': 'France', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/france.json'}\n",
      "{'location_id': 'hong-kong-hong-kong', 'province_state': 'Hong Kong', 'country_region': 'Hong Kong', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/hong-kong-hong-kong.json'}\n",
      "{'location_id': 'japan', 'province_state': '', 'country_region': 'Japan', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/japan.json'}\n",
      "{'location_id': 'macau-macau', 'province_state': 'Macau', 'country_region': 'Macau', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/macau-macau.json'}\n",
      "{'location_id': 'mainland-china-anhui', 'province_state': 'Anhui', 'country_region': 'Mainland China', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/mainland-china-anhui.json'}\n",
      "{'location_id': 'mainland-china-beijing', 'province_state': 'Beijing', 'country_region': 'Mainland China', 'cloud_resource': 'https://thecodinginterface-covid.s3.amazonaws.com/mainland-china-beijing.json'}\n"
     ]
    }
   ],
   "source": [
    "# create a list of dicts in the form:\n",
    "# [ \n",
    "#   {\n",
    "#     country_region: str,\n",
    "#     province_state: str,\n",
    "#     lat: float,\n",
    "#     long: float,\n",
    "#     filename: str,\n",
    "#     cloud_resource: str\n",
    "#   },\n",
    "#    ...\n",
    "# ]\n",
    "locations = []\n",
    "location_groups = locations_df.groupby(['location_id'])\n",
    "for k, location_data in location_groups:\n",
    "    for i, row in location_data.iterrows():\n",
    "        data = row.to_dict()\n",
    "        locations.append(data)\n",
    "        if i < 5:\n",
    "            print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize locations to JSON file\n",
    "with open('locations.json', 'w') as fo:\n",
    "    json.dump(locations, fo, indent=4)\n",
    "\n",
    "#!head -n 15 locations.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country / Region Dashboard\n",
    "\n",
    "Give user ability to select (aka drill down) into country, region, state, province\n",
    "\n",
    "Show confirmed, deaths, recovered\n",
    "\n",
    "Show time series of total confirmed\n",
    "\n",
    "Show time series of total recovered\n",
    "\n",
    "Show time series of total deaths\n",
    "\n",
    "Show time series of daily new confirmed\n",
    "\n",
    "Show time series of daily new recovered\n",
    "\n",
    "Show time series of daily new deaths\n",
    "\n",
    "Would be interesting to give a Gauge chart next to the daily graphs with an indicator of direction of n day movement (ie, over the last three days is new daily cases (deaths, confirmed, recovered) increasing, descreasing, maintaining)\n",
    "\n",
    "\n",
    "## Location Comparisons\n",
    "\n",
    "### Barcharts\n",
    "\n",
    "Death Rates: select locations to include and date in time (includes checkbox to make percent of population)\n",
    "\n",
    "Confirmed Counts: select locations to include and date in time (includes checkbox to make percent of population)\n",
    "\n",
    "\n",
    "### Line Charts\n",
    "\n",
    "Total Confirmed Cases: select locations to include and plot progression of cases since first case (includes checkbox to make percent of population)\n",
    "\n",
    "New Daily Confirmed Cases: select locations to include and plot progression of new cases since first case in each location (includes checkbox to make percent of population)\n",
    "\n",
    "Total Deaths: select locations to include and plot progression of deaths since first case (includes checkbox to make percent of population)\n",
    "\n",
    "New Daily Deaths: select locations to include and plot progression of deaths since first  case in each location (includes checkbox to make percent of population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df.to_csv('locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
