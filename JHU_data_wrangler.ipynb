{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### John Hopkins GitHub Repo Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import uuid\n",
    "from slugify import slugify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__name__))), 'COVID-19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the confirmed cases time series files in here have Lat and Long for each location\n",
    "# confirmed_series_file = os.path.join(\n",
    "#     DATA_DIR,\n",
    "#     'csse_covid_19_data',\n",
    "#     'csse_covid_19_time_series',\n",
    "#     'time_series_covid19_confirmed_global.csv'\n",
    "# )\n",
    "# confirmed_series_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 10 rows of time_series_19-covid-Confirmed.csv file\n",
    "#!awk -F, '{print $1,$2,$3,$4} NR==10{exit}' OFS=', ' \\\n",
    "# COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols=['Province/State', 'Country/Region', 'Lat', 'Long']\n",
    "# locations_df = pd.read_csv(confirmed_series_file, usecols=cols)\n",
    "# locations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = boto3.resource('s3')\n",
    "bucket_name = 'thecodinginterface-covid'\n",
    "s3_bucket = s3_resource.Bucket(name=bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slugify_location(country_region, province_state):\n",
    "    if province_state:\n",
    "        return slugify(f\"{country_region}-{province_state}\")\n",
    "    return slugify(country_region)\n",
    "\n",
    "def cloud_resource_url(filename, bucket_name):\n",
    "    return f\"https://{bucket_name}.s3.amazonaws.com/{filename}.json\"\n",
    "\n",
    "def upload_file_to_s3(s3_bucket, file_path, file_name):\n",
    "    s3_bucket.upload_file(\n",
    "        Filename=file_path,\n",
    "        Key=file_name,\n",
    "        ExtraArgs={'ACL':'public-read'}\n",
    "    )\n",
    "    return cloud_resource_url(file_name, s3_bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be snake_cased making it more ammenable to serialization\n",
    "# locations_df = locations_df.rename(columns={\n",
    "#     'Province/State': 'province_state',\n",
    "#     'Country/Region': 'country_region',\n",
    "#     'Lat': 'lat',\n",
    "#     'Long': 'long'\n",
    "# })\n",
    "\n",
    "# # make sure text columns are well cleaned and stripped of whitespace\n",
    "# locations_df.province_state = locations_df.province_state.str.strip()\n",
    "# locations_df.country_region = locations_df.country_region.str.strip()\n",
    "\n",
    "# # Fill NaNs with empty strings in the Province/State columns because this data will\n",
    "# # be serialized into JSON which does not support NaN\n",
    "# locations_df.province_state = locations_df.province_state.fillna('')\n",
    "\n",
    "# # create columns \"filename\" and \"cloud_resource\"\n",
    "# lookup_keys = zip(locations_df.country_region, locations_df.province_state)\n",
    "# locations_df['location_id'] = [slugify_location(country_region, province_state)\n",
    "#                             for country_region, province_state in lookup_keys]\n",
    "\n",
    "# locations_df['cloud_resource'] = [cloud_resource_url(filename, bucket_name)\n",
    "#                                   for filename in locations_df['location_id'].values]\n",
    "\n",
    "# locations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations_df.country_region.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations_df = locations_df.set_index('location_id')\n",
    "# locations_df[locations_df.country_region == 'US'].sort_values('province_state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll do more with this locations_df DataFrame later after\n",
    "# constructing country specific case data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02-26-2020.csv',\n",
       " '02-27-2020.csv',\n",
       " '04-08-2020.csv',\n",
       " '04-09-2020.csv',\n",
       " '02-18-2020.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build list of daily csv files\n",
    "daily_series_dir = os.path.join(\n",
    "    DATA_DIR,\n",
    "    'csse_covid_19_data',\n",
    "    'csse_covid_19_daily_reports'\n",
    ")\n",
    "daily_csv_files = [file_name\n",
    "                   for file_name in os.listdir(daily_series_dir) \n",
    "                   if file_name.endswith('csv')]\n",
    "daily_csv_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/adammcquistan/Code/python/COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/03-08-2020.csv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a peek at the structure of a file that will be worked with\n",
    "os.path.join(daily_series_dir, daily_csv_files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head ./COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/02-26-2020.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_differential(x):\n",
    "    x0 = np.array([0] + x[:-1].tolist())\n",
    "    dx = x.values - x0\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>total_confirmed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>total_recovered</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Algeria</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Australia</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From Diamond Princess</td>\n",
       "      <td>Australia</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Queensland</td>\n",
       "      <td>Australia</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Victoria</td>\n",
       "      <td>Australia</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>Austria</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          province_state country_region  total_confirmed  total_deaths  \\\n",
       "0                           Afghanistan              2.0           0.0   \n",
       "1                               Algeria              2.0           0.0   \n",
       "2                             Australia             22.0           0.0   \n",
       "3  From Diamond Princess      Australia              7.0           0.0   \n",
       "4        New South Wales      Australia              4.0           0.0   \n",
       "5             Queensland      Australia              5.0           0.0   \n",
       "6        South Australia      Australia              2.0           0.0   \n",
       "7               Victoria      Australia              4.0           0.0   \n",
       "8                               Austria              4.0           0.0   \n",
       "9                               Bahrain             66.0           0.0   \n",
       "\n",
       "   total_recovered       date  \n",
       "0              0.0 2020-02-26  \n",
       "1              0.0 2020-02-26  \n",
       "2             11.0 2020-02-26  \n",
       "3              0.0 2020-02-26  \n",
       "4              4.0 2020-02-26  \n",
       "5              1.0 2020-02-26  \n",
       "6              2.0 2020-02-26  \n",
       "7              4.0 2020-02-26  \n",
       "8              0.0 2020-02-26  \n",
       "9              0.0 2020-02-26  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the daily files into DataFrame objects then concatenate them together\n",
    "daily_dfs = []\n",
    "colunns_of_interest = [\n",
    "    'province_state',\n",
    "    'country_region',\n",
    "    'total_confirmed',\n",
    "    'total_deaths',\n",
    "    'total_recovered',\n",
    "    'date'\n",
    "]\n",
    "\n",
    "for file_name in daily_csv_files:\n",
    "    file_path = os.path.join(daily_series_dir, file_name)\n",
    "    day_df = pd.read_csv(file_path)\n",
    "\n",
    "    # Province_State and Country_Region replaced column names Province/State\n",
    "    # and Country/Region for new daily files starting 03-24-2020\n",
    "    day_df = day_df.rename(columns={\n",
    "            'Province/State': 'province_state',\n",
    "            'Province_State': 'province_state', \n",
    "            'Country/Region': 'country_region',\n",
    "            'Country_Region': 'country_region',\n",
    "            'Confirmed': 'total_confirmed',\n",
    "            'Deaths':'total_deaths',\n",
    "            'Recovered': 'total_recovered'\n",
    "        })\n",
    "    \n",
    "    date_str, ext = os.path.splitext(file_name)\n",
    "    num_rows = day_df.shape[0]\n",
    "    day_df['date'] = [pd.to_datetime(date_str)] * num_rows\n",
    "\n",
    "    # Fill NaNs with empty strings because this data will\n",
    "    # be serialized into JSON which does not support NaN\n",
    "    day_df.province_state = day_df.province_state.fillna('')\n",
    "    day_df.total_confirmed = day_df.total_confirmed.fillna(0)\n",
    "    day_df.total_deaths = day_df.total_deaths.fillna(0)\n",
    "    day_df.total_recovered = day_df.total_recovered.fillna(0)\n",
    "\n",
    "    missing_columns = sum([(col not in day_df.columns) for col in colunns_of_interest])\n",
    "    if missing_columns:\n",
    "        print('Missing Columns!!!!')\n",
    "        sys.exit(0)\n",
    "\n",
    "    whole_country_df = day_df[colunns_of_interest].groupby(['country_region']).sum()\n",
    "    whole_country_df = whole_country_df.reset_index()\n",
    "    whole_country_df['province_state'] = [''] * whole_country_df.shape[0]\n",
    "    whole_country_df['date'] = [day_df.date.values[0]] * whole_country_df.shape[0]\n",
    "    whole_country_df.loc[whole_country_df['country_region'] == 'US', ['country_region']] = 'United States'\n",
    "        \n",
    "    if 'Admin2' in day_df.columns:\n",
    "        county_df = day_df[day_df.Admin2 != '']\n",
    "        county_df['province_state'] = county_df.Admin2 + ', ' + county_df.province_state\n",
    "        day_df = pd.concat([day_df[colunns_of_interest], county_df[colunns_of_interest], whole_country_df])\n",
    "    else:\n",
    "        day_df = pd.concat([day_df[colunns_of_interest], whole_country_df])\n",
    "    \n",
    "#     day_df = day_df[colunns_of_interest]\n",
    "    \n",
    "    # increased granularity by neighborhood was added in Admin2 column 03-24-2020\n",
    "    # but only want granularity down to province_region so collapse down and aggregate\n",
    "    day_df = day_df.groupby(['country_region', 'province_state', 'date']).sum()\n",
    "    day_df = day_df.reset_index()\n",
    "    \n",
    "    daily_dfs.append(day_df[colunns_of_interest])\n",
    "    \n",
    "daily_df = pd.concat(daily_dfs)\n",
    "# make sure text columns are well cleaned and stripped of whitespace\n",
    "daily_df.province_state = daily_df.province_state.str.strip()\n",
    "daily_df.country_region = daily_df.country_region.str.strip()\n",
    "daily_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>total_confirmed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>total_recovered</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2810</th>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>337072.0</td>\n",
       "      <td>9619.0</td>\n",
       "      <td>17448.0</td>\n",
       "      <td>2020-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>366667.0</td>\n",
       "      <td>10783.0</td>\n",
       "      <td>19581.0</td>\n",
       "      <td>2020-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>396223.0</td>\n",
       "      <td>12722.0</td>\n",
       "      <td>21763.0</td>\n",
       "      <td>2020-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>429052.0</td>\n",
       "      <td>14695.0</td>\n",
       "      <td>23559.0</td>\n",
       "      <td>2020-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>461437.0</td>\n",
       "      <td>16478.0</td>\n",
       "      <td>25410.0</td>\n",
       "      <td>2020-04-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     province_state country_region  total_confirmed  total_deaths  \\\n",
       "42                   United States              1.0           0.0   \n",
       "49                   United States              1.0           0.0   \n",
       "44                   United States              2.0           0.0   \n",
       "47                   United States              2.0           0.0   \n",
       "51                   United States              5.0           0.0   \n",
       "...             ...            ...              ...           ...   \n",
       "2810                 United States         337072.0        9619.0   \n",
       "2855                 United States         366667.0       10783.0   \n",
       "2903                 United States         396223.0       12722.0   \n",
       "2929                 United States         429052.0       14695.0   \n",
       "2957                 United States         461437.0       16478.0   \n",
       "\n",
       "      total_recovered       date  \n",
       "42                0.0 2020-01-22  \n",
       "49                0.0 2020-01-23  \n",
       "44                0.0 2020-01-24  \n",
       "47                0.0 2020-01-25  \n",
       "51                0.0 2020-01-26  \n",
       "...               ...        ...  \n",
       "2810          17448.0 2020-04-05  \n",
       "2855          19581.0 2020-04-06  \n",
       "2903          21763.0 2020-04-07  \n",
       "2929          23559.0 2020-04-08  \n",
       "2957          25410.0 2020-04-09  \n",
       "\n",
       "[79 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_df[daily_df['country_region'] == 'United States'].sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole_country_df = daily_df.groupby(['country_region', 'date']).sum()\n",
    "# whole_country_df = whole_country_df.reset_index()\n",
    "# whole_country_df['province_state'] = [''] * whole_country_df.shape[0]\n",
    "# whole_country_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>total_confirmed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>total_recovered</th>\n",
       "      <th>date</th>\n",
       "      <th>location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>421.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>525.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>732.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>967.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>2495.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>5365.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>8310.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>11710.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>15800.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>20884.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>25681.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>30841.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>37877.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>44876.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>52410.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>59648.0</td>\n",
       "      <td>965.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>66663.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>75833.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>83948.0</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>92506.0</td>\n",
       "      <td>2373.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>102987.0</td>\n",
       "      <td>2935.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>113833.0</td>\n",
       "      <td>3565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>123160.0</td>\n",
       "      <td>4159.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>131815.0</td>\n",
       "      <td>4698.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>139875.0</td>\n",
       "      <td>5489.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>151061.0</td>\n",
       "      <td>6268.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>161779.0</td>\n",
       "      <td>7067.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>us-new-york</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     province_state country_region  total_confirmed  total_deaths  \\\n",
       "190        New York             US            173.0           0.0   \n",
       "197        New York             US            220.0           0.0   \n",
       "199        New York             US            328.0           0.0   \n",
       "211        New York             US            421.0           0.0   \n",
       "225        New York             US            525.0           2.0   \n",
       "233        New York             US            732.0           3.0   \n",
       "247        New York             US            967.0          10.0   \n",
       "251        New York             US           1706.0          13.0   \n",
       "256        New York             US           2495.0          16.0   \n",
       "263        New York             US           5365.0          34.0   \n",
       "269        New York             US           8310.0          42.0   \n",
       "273        New York             US          11710.0          60.0   \n",
       "2333       New York             US          15800.0         117.0   \n",
       "2328       New York             US          20884.0         158.0   \n",
       "2329       New York             US          25681.0         210.0   \n",
       "2333       New York             US          30841.0         285.0   \n",
       "2335       New York             US          37877.0         385.0   \n",
       "2336       New York             US          44876.0         527.0   \n",
       "2337       New York             US          52410.0         728.0   \n",
       "2337       New York             US          59648.0         965.0   \n",
       "2338       New York             US          66663.0        1218.0   \n",
       "1670       New York             US          75833.0        1550.0   \n",
       "1709       New York             US          83948.0        1941.0   \n",
       "1765       New York             US          92506.0        2373.0   \n",
       "1796       New York             US         102987.0        2935.0   \n",
       "1834       New York             US         113833.0        3565.0   \n",
       "1887       New York             US         123160.0        4159.0   \n",
       "1914       New York             US         131815.0        4698.0   \n",
       "1950       New York             US         139875.0        5489.0   \n",
       "1965       New York             US         151061.0        6268.0   \n",
       "1984       New York             US         161779.0        7067.0   \n",
       "\n",
       "      total_recovered       date  location_id  \n",
       "190               0.0 2020-03-10  us-new-york  \n",
       "197               0.0 2020-03-11  us-new-york  \n",
       "199               0.0 2020-03-12  us-new-york  \n",
       "211               0.0 2020-03-13  us-new-york  \n",
       "225               0.0 2020-03-14  us-new-york  \n",
       "233               0.0 2020-03-15  us-new-york  \n",
       "247               0.0 2020-03-16  us-new-york  \n",
       "251               0.0 2020-03-17  us-new-york  \n",
       "256               0.0 2020-03-18  us-new-york  \n",
       "263               0.0 2020-03-19  us-new-york  \n",
       "269               0.0 2020-03-20  us-new-york  \n",
       "273               0.0 2020-03-21  us-new-york  \n",
       "2333              0.0 2020-03-22  us-new-york  \n",
       "2328              0.0 2020-03-23  us-new-york  \n",
       "2329              0.0 2020-03-24  us-new-york  \n",
       "2333              0.0 2020-03-25  us-new-york  \n",
       "2335              0.0 2020-03-26  us-new-york  \n",
       "2336              0.0 2020-03-27  us-new-york  \n",
       "2337              0.0 2020-03-28  us-new-york  \n",
       "2337              0.0 2020-03-29  us-new-york  \n",
       "2338              0.0 2020-03-30  us-new-york  \n",
       "1670              0.0 2020-03-31  us-new-york  \n",
       "1709              0.0 2020-04-01  us-new-york  \n",
       "1765              0.0 2020-04-02  us-new-york  \n",
       "1796              0.0 2020-04-03  us-new-york  \n",
       "1834              0.0 2020-04-04  us-new-york  \n",
       "1887              0.0 2020-04-05  us-new-york  \n",
       "1914              0.0 2020-04-06  us-new-york  \n",
       "1950              0.0 2020-04-07  us-new-york  \n",
       "1965              0.0 2020-04-08  us-new-york  \n",
       "1984              0.0 2020-04-09  us-new-york  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# daily_df = pd.concat([daily_df, whole_country_df])\n",
    "daily_df = daily_df.drop_duplicates()\n",
    "locations = zip(daily_df.country_region.values, daily_df.province_state.values)\n",
    "daily_df['location_id'] = [slugify_location(country_region, province_state)\n",
    "                           for country_region, province_state in locations]\n",
    "\n",
    "# sort by country_region, province_state, date\n",
    "daily_df = daily_df.sort_values(['country_region', 'province_state', 'date'])\n",
    "daily_df[(daily_df.country_region == 'US') & (daily_df.province_state == 'New York')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_counts = daily_df.groupby('location_id').count().sort_values('date')\n",
    "entry_counts = entry_counts[entry_counts.date < 20]\n",
    "for loc_id in entry_counts.index.values:\n",
    "    daily_df = daily_df[daily_df.location_id != loc_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_confirmed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>total_recovered</th>\n",
       "      <th>death_rate</th>\n",
       "      <th>recovery_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>united-states</th>\n",
       "      <td>461437.0</td>\n",
       "      <td>16478.0</td>\n",
       "      <td>25410.0</td>\n",
       "      <td>3.571018</td>\n",
       "      <td>5.506711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spain</th>\n",
       "      <td>306444.0</td>\n",
       "      <td>30894.0</td>\n",
       "      <td>104330.0</td>\n",
       "      <td>10.081450</td>\n",
       "      <td>34.045372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>italy</th>\n",
       "      <td>287252.0</td>\n",
       "      <td>36558.0</td>\n",
       "      <td>56940.0</td>\n",
       "      <td>12.726804</td>\n",
       "      <td>19.822316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>france</th>\n",
       "      <td>236530.0</td>\n",
       "      <td>24438.0</td>\n",
       "      <td>46619.0</td>\n",
       "      <td>10.331882</td>\n",
       "      <td>19.709551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>germany</th>\n",
       "      <td>236362.0</td>\n",
       "      <td>5214.0</td>\n",
       "      <td>104814.0</td>\n",
       "      <td>2.205938</td>\n",
       "      <td>44.344692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us-new-york</th>\n",
       "      <td>161779.0</td>\n",
       "      <td>7067.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.368305</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iran</th>\n",
       "      <td>132440.0</td>\n",
       "      <td>8220.0</td>\n",
       "      <td>64618.0</td>\n",
       "      <td>6.206584</td>\n",
       "      <td>48.790396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united-kingdom</th>\n",
       "      <td>130949.0</td>\n",
       "      <td>15971.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>12.196351</td>\n",
       "      <td>0.377246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us-new-york-city-new-york</th>\n",
       "      <td>87028.0</td>\n",
       "      <td>5150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.917636</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turkey</th>\n",
       "      <td>84564.0</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>4284.0</td>\n",
       "      <td>2.147486</td>\n",
       "      <td>5.065986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           total_confirmed  total_deaths  total_recovered  \\\n",
       "location_id                                                                 \n",
       "united-states                     461437.0       16478.0          25410.0   \n",
       "spain                             306444.0       30894.0         104330.0   \n",
       "italy                             287252.0       36558.0          56940.0   \n",
       "france                            236530.0       24438.0          46619.0   \n",
       "germany                           236362.0        5214.0         104814.0   \n",
       "us-new-york                       161779.0        7067.0              0.0   \n",
       "iran                              132440.0        8220.0          64618.0   \n",
       "united-kingdom                    130949.0       15971.0            494.0   \n",
       "us-new-york-city-new-york          87028.0        5150.0              0.0   \n",
       "turkey                             84564.0        1816.0           4284.0   \n",
       "\n",
       "                           death_rate  recovery_rate  \n",
       "location_id                                           \n",
       "united-states                3.571018       5.506711  \n",
       "spain                       10.081450      34.045372  \n",
       "italy                       12.726804      19.822316  \n",
       "france                      10.331882      19.709551  \n",
       "germany                      2.205938      44.344692  \n",
       "us-new-york                  4.368305       0.000000  \n",
       "iran                         6.206584      48.790396  \n",
       "united-kingdom              12.196351       0.377246  \n",
       "us-new-york-city-new-york    5.917636       0.000000  \n",
       "turkey                       2.147486       5.065986  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get totals per location\n",
    "max_date = daily_df.date.max()\n",
    "rows_of_interest = daily_df.date == max_date\n",
    "columns_of_interest = [\n",
    "    'location_id',\n",
    "    'total_confirmed',\n",
    "    'total_deaths',\n",
    "    'total_recovered'\n",
    "]\n",
    "location_totals_df = daily_df.loc[rows_of_interest, columns_of_interest]\n",
    "location_totals_df = location_totals_df.groupby('location_id').sum()\n",
    "location_totals_df['death_rate'] = location_totals_df.total_deaths / location_totals_df.total_confirmed * 100\n",
    "location_totals_df['recovery_rate'] = location_totals_df.total_recovered / location_totals_df.total_confirmed * 100\n",
    "location_totals_df.sort_values('total_confirmed', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get totals per country / region\n",
    "# country_totals_df = locations_df.join(location_totals_df)\n",
    "# columns_of_interest = [\n",
    "#     'country_region',\n",
    "#     'total_confirmed',\n",
    "#     'total_deaths',\n",
    "#     'total_recovered',\n",
    "# ]\n",
    "# country_totals_df = country_totals_df.reset_index()\n",
    "# country_totals_df = country_totals_df[columns_of_interest].groupby('country_region').sum()\n",
    "# country_totals_df['death_rate'] = country_totals_df.total_deaths / country_totals_df.total_confirmed * 100\n",
    "# country_totals_df['recovery_rate'] = country_totals_df.total_recovered / country_totals_df.total_confirmed * 100\n",
    "# country_totals_df.sort_values('country_region').head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# world_population_df = pd.read_csv('world_population.csv')\n",
    "# world_population_df = world_population_df.set_index('country_region')\n",
    "# world_population_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add population data to country totals\n",
    "# country_totals_df = country_totals_df.join(world_population_df)\n",
    "# country_totals_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>total_confirmed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>total_recovered</th>\n",
       "      <th>date</th>\n",
       "      <th>location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>9654.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>12305.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>14904.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>17856.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>21873.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>25573.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>29776.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>33768.0</td>\n",
       "      <td>678.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>37453.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>43119.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>47439.0</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>51809.0</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>57159.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>63306.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>67551.0</td>\n",
       "      <td>2256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>72181.0</td>\n",
       "      <td>3485.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>76876.0</td>\n",
       "      <td>4009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>81803.0</td>\n",
       "      <td>4571.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>US</td>\n",
       "      <td>87028.0</td>\n",
       "      <td>5150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>us-new-york-city-new-york</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               province_state country_region  total_confirmed  total_deaths  \\\n",
       "2334  New York City, New York             US           9654.0          63.0   \n",
       "2329  New York City, New York             US          12305.0          99.0   \n",
       "2330  New York City, New York             US          14904.0         131.0   \n",
       "2334  New York City, New York             US          17856.0         199.0   \n",
       "2336  New York City, New York             US          21873.0         281.0   \n",
       "2337  New York City, New York             US          25573.0         366.0   \n",
       "2338  New York City, New York             US          29776.0         517.0   \n",
       "2338  New York City, New York             US          33768.0         678.0   \n",
       "2339  New York City, New York             US          37453.0         790.0   \n",
       "1671  New York City, New York             US          43119.0         932.0   \n",
       "1710  New York City, New York             US          47439.0        1139.0   \n",
       "1766  New York City, New York             US          51809.0        1397.0   \n",
       "1797  New York City, New York             US          57159.0        1584.0   \n",
       "1835  New York City, New York             US          63306.0        1905.0   \n",
       "1888  New York City, New York             US          67551.0        2256.0   \n",
       "1915  New York City, New York             US          72181.0        3485.0   \n",
       "1951  New York City, New York             US          76876.0        4009.0   \n",
       "1966  New York City, New York             US          81803.0        4571.0   \n",
       "1985  New York City, New York             US          87028.0        5150.0   \n",
       "\n",
       "      total_recovered       date                location_id  \n",
       "2334              0.0 2020-03-22  us-new-york-city-new-york  \n",
       "2329              0.0 2020-03-23  us-new-york-city-new-york  \n",
       "2330              0.0 2020-03-24  us-new-york-city-new-york  \n",
       "2334              0.0 2020-03-25  us-new-york-city-new-york  \n",
       "2336              0.0 2020-03-26  us-new-york-city-new-york  \n",
       "2337              0.0 2020-03-27  us-new-york-city-new-york  \n",
       "2338              0.0 2020-03-28  us-new-york-city-new-york  \n",
       "2338              0.0 2020-03-29  us-new-york-city-new-york  \n",
       "2339              0.0 2020-03-30  us-new-york-city-new-york  \n",
       "1671              0.0 2020-03-31  us-new-york-city-new-york  \n",
       "1710              0.0 2020-04-01  us-new-york-city-new-york  \n",
       "1766              0.0 2020-04-02  us-new-york-city-new-york  \n",
       "1797              0.0 2020-04-03  us-new-york-city-new-york  \n",
       "1835              0.0 2020-04-04  us-new-york-city-new-york  \n",
       "1888              0.0 2020-04-05  us-new-york-city-new-york  \n",
       "1915              0.0 2020-04-06  us-new-york-city-new-york  \n",
       "1951              0.0 2020-04-07  us-new-york-city-new-york  \n",
       "1966              0.0 2020-04-08  us-new-york-city-new-york  \n",
       "1985              0.0 2020-04-09  us-new-york-city-new-york  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_df[(daily_df.country_region == 'US') & (daily_df.location_id == 'us-new-york-city-new-york')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading azerbaijan 20 of 2948\n",
      "Uploading canada 40 of 2948\n",
      "Uploading chile 60 of 2948\n",
      "Uploading china-jilin 80 of 2948\n",
      "Uploading croatia 100 of 2948\n",
      "Uploading ethiopia 120 of 2948\n",
      "Uploading grenada 140 of 2948\n",
      "Uploading japan 160 of 2948\n",
      "Uploading mainland-china-anhui 180 of 2948\n",
      "Uploading mainland-china-qinghai 200 of 2948\n",
      "Uploading monaco 220 of 2948\n",
      "Uploading others-diamond-princess-cruise-ship 240 of 2948\n",
      "Uploading seychelles 260 of 2948\n",
      "Uploading trinidad-and-tobago 280 of 2948\n",
      "Uploading us-acadia-louisiana 300 of 2948\n",
      "Uploading us-alachua-florida 320 of 2948\n",
      "Uploading us-allen-louisiana 340 of 2948\n",
      "Uploading us-antelope-nebraska 360 of 2948\n",
      "Uploading us-ashley-arkansas 380 of 2948\n",
      "Uploading us-bacon-georgia 400 of 2948\n",
      "Uploading us-barry-missouri 420 of 2948\n",
      "Uploading us-bedford-pennsylvania 440 of 2948\n",
      "Uploading us-berkeley-south-carolina 460 of 2948\n",
      "Uploading us-blanco-texas 480 of 2948\n",
      "Uploading us-boston-ma 500 of 2948\n",
      "Uploading us-breckinridge-kentucky 520 of 2948\n",
      "Uploading us-brunswick-virginia 540 of 2948\n",
      "Uploading us-burleson-texas 560 of 2948\n",
      "Uploading us-caldwell-kentucky 580 of 2948\n",
      "Uploading us-camas-idaho 600 of 2948\n",
      "Uploading us-carbon-pennsylvania 620 of 2948\n",
      "Uploading us-carter-kentucky 640 of 2948\n",
      "Uploading us-catron-new-mexico 660 of 2948\n",
      "Uploading us-charlotte-virginia 680 of 2948\n",
      "Uploading us-cherokee-south-carolina 700 of 2948\n",
      "Uploading us-choctaw-alabama 720 of 2948\n",
      "Uploading us-clark-kentucky 740 of 2948\n",
      "Uploading us-clay-minnesota 760 of 2948\n",
      "Uploading us-clinton-indiana 780 of 2948\n",
      "Uploading us-cole-missouri 800 of 2948\n",
      "Uploading us-comal-texas 820 of 2948\n",
      "Uploading us-cottonwood-minnesota 840 of 2948\n",
      "Uploading us-crawford-ohio 860 of 2948\n",
      "Uploading us-cumberland-new-jersey 880 of 2948\n",
      "Uploading us-dallas-iowa 900 of 2948\n",
      "Uploading us-de-witt-illinois 920 of 2948\n",
      "Uploading us-delaware-oklahoma 940 of 2948\n",
      "Uploading us-dinwiddie-virginia 960 of 2948\n",
      "Uploading us-douglas-kansas 980 of 2948\n",
      "Uploading us-dyer-tennessee 1000 of 2948\n",
      "Uploading us-el-paso-texas 1020 of 2948\n",
      "Uploading us-essex-massachusetts 1040 of 2948\n",
      "Uploading us-fauquier-virginia 1060 of 2948\n",
      "Uploading us-florida 1080 of 2948\n",
      "Uploading us-franklin-georgia 1100 of 2948\n",
      "Uploading us-frederick-maryland 1120 of 2948\n",
      "Uploading us-galveston-texas 1140 of 2948\n",
      "Uploading us-gibson-tennessee 1160 of 2948\n",
      "Uploading us-gordon-georgia 1180 of 2948\n",
      "Uploading us-grant-north-dakota 1200 of 2948\n",
      "Uploading us-greene-missouri 1220 of 2948\n",
      "Uploading us-guadalupe-texas 1240 of 2948\n",
      "Uploading us-hamilton-new-york 1260 of 2948\n",
      "Uploading us-haralson-georgia 1280 of 2948\n",
      "Uploading us-harrisonburg-virginia 1300 of 2948\n",
      "Uploading us-henrico-virginia 1320 of 2948\n",
      "Uploading us-hillsborough-florida 1340 of 2948\n",
      "Uploading us-houston-georgia 1360 of 2948\n",
      "Uploading us-huntington-indiana 1380 of 2948\n",
      "Uploading us-iowa-iowa 1400 of 2948\n",
      "Uploading us-jackson-kansas 1420 of 2948\n",
      "Uploading us-jasper-south-carolina 1440 of 2948\n",
      "Uploading us-jefferson-new-york 1460 of 2948\n",
      "Uploading us-johnson-iowa 1480 of 2948\n",
      "Uploading us-kandiyohi-minnesota 1500 of 2948\n",
      "Uploading us-kent-rhode-island 1520 of 2948\n",
      "Uploading us-kittitas-washington 1540 of 2948\n",
      "Uploading us-lackawanna-pennsylvania 1560 of 2948\n",
      "Uploading us-lamar-mississippi 1580 of 2948\n",
      "Uploading us-latimer-oklahoma 1600 of 2948\n",
      "Uploading us-lea-new-mexico 1620 of 2948\n",
      "Uploading us-leon-florida 1640 of 2948\n",
      "Uploading us-lincoln-colorado 1660 of 2948\n",
      "Uploading us-linn-missouri 1680 of 2948\n",
      "Uploading us-lorain-ohio 1700 of 2948\n",
      "Uploading us-lyman-south-dakota 1720 of 2948\n",
      "Uploading us-madison-georgia 1740 of 2948\n",
      "Uploading us-major-oklahoma 1760 of 2948\n",
      "Uploading us-marion-kentucky 1780 of 2948\n",
      "Uploading us-martin-florida 1800 of 2948\n",
      "Uploading us-maury-tennessee 1820 of 2948\n",
      "Uploading us-mckenzie-north-dakota 1840 of 2948\n",
      "Uploading us-meigs-tennessee 1860 of 2948\n",
      "Uploading us-miami-ohio 1880 of 2948\n",
      "Uploading us-mississippi 1900 of 2948\n",
      "Uploading us-monroe-georgia 1920 of 2948\n",
      "Uploading us-montgomery-kentucky 1940 of 2948\n",
      "Uploading us-morgan-illinois 1960 of 2948\n",
      "Uploading us-muscatine-iowa 1980 of 2948\n",
      "Uploading us-neshoba-mississippi 2000 of 2948\n",
      "Uploading us-newton-georgia 2020 of 2948\n",
      "Uploading us-northern-mariana-islands 2040 of 2948\n",
      "Uploading us-ohio 2060 of 2948\n",
      "Uploading us-ontario-new-york 2080 of 2948\n",
      "Uploading us-osborne-kansas 2100 of 2948\n",
      "Uploading us-outagamie-wisconsin 2120 of 2948\n",
      "Uploading us-passaic-new-jersey 2140 of 2948\n",
      "Uploading us-perquimans-north-carolina 2160 of 2948\n",
      "Uploading us-pickens-alabama 2180 of 2948\n",
      "Uploading us-pitkin-colorado 2200 of 2948\n",
      "Uploading us-polk-missouri 2220 of 2948\n",
      "Uploading us-poweshiek-iowa 2240 of 2948\n",
      "Uploading us-pulaski-virginia 2260 of 2948\n",
      "Uploading us-randolph-arkansas 2280 of 2948\n",
      "Uploading us-reynolds-missouri 2300 of 2948\n",
      "Uploading us-roane-west-virginia 2320 of 2948\n",
      "Uploading us-roosevelt-new-mexico 2340 of 2948\n",
      "Uploading us-salem-new-jersey 2360 of 2948\n",
      "Uploading us-san-juan-utah 2380 of 2948\n",
      "Uploading us-sarpy-nebraska 2400 of 2948\n",
      "Uploading us-scott-tennessee 2420 of 2948\n",
      "Uploading us-sharp-arkansas 2440 of 2948\n",
      "Uploading us-simpson-kentucky 2460 of 2948\n",
      "Uploading us-sonoma-california 2480 of 2948\n",
      "Uploading us-st-francois-missouri 2500 of 2948\n",
      "Uploading us-stanly-north-carolina 2520 of 2948\n",
      "Uploading us-stokes-north-carolina 2540 of 2948\n",
      "Uploading us-sumter-alabama 2560 of 2948\n",
      "Uploading us-talladega-alabama 2580 of 2948\n",
      "Uploading us-teller-colorado 2600 of 2948\n",
      "Uploading us-tipton-indiana 2620 of 2948\n",
      "Uploading us-troup-georgia 2640 of 2948\n",
      "Uploading us-umatilla-oregon 2660 of 2948\n",
      "Uploading us-unassigned-nebraska 2680 of 2948\n",
      "Uploading us-union-ohio 2700 of 2948\n",
      "Uploading us-van-zandt-texas 2720 of 2948\n",
      "Uploading us-wabaunsee-kansas 2740 of 2948\n",
      "Uploading us-warren-georgia 2760 of 2948\n",
      "Uploading us-washington-arkansas 2780 of 2948\n",
      "Uploading us-washington-pennsylvania 2800 of 2948\n",
      "Uploading us-wayne-mississippi 2820 of 2948\n",
      "Uploading us-west-feliciana-louisiana 2840 of 2948\n",
      "Uploading us-wicomico-maryland 2860 of 2948\n",
      "Uploading us-winchester-virginia 2880 of 2948\n",
      "Uploading us-woodbury-iowa 2900 of 2948\n",
      "Uploading us-yadkin-north-carolina 2920 of 2948\n",
      "Uploading us-yuma-arizona 2940 of 2948\n"
     ]
    }
   ],
   "source": [
    "# group by location and serialize each location dataset to a json file\n",
    "# [ \n",
    "#   {\n",
    "#     date: str,\n",
    "#     province_state: str,\n",
    "#     confirmed: int,\n",
    "#     deaths: int,\n",
    "#     recovered: int\n",
    "#   }, ...\n",
    "# ]\n",
    "\n",
    "location_case_data = 'location_case_data'\n",
    "if not os.path.exists(location_case_data):\n",
    "    os.mkdir(location_case_data)\n",
    "\n",
    "location_groups = daily_df.groupby(['location_id'])\n",
    "groups = len(location_groups)\n",
    "i = 1\n",
    "for location_id, location_data in location_groups:\n",
    "    location_data = location_data.sort_values('date')\n",
    "    location_data.loc[:,'daily_confirmed'] = calc_differential(location_data.total_confirmed)\n",
    "    location_data.loc[:,'daily_deaths'] = calc_differential(location_data.total_deaths)\n",
    "    location_data.loc[:,'daily_recovered'] = calc_differential(location_data.total_recovered)\n",
    "    \n",
    "    location_days = []\n",
    "\n",
    "    for idx, row in location_data.iterrows():\n",
    "        data = row.to_dict()\n",
    "        # dates don't serialize well in Python so, convert to strings\n",
    "        data['date'] = data['date'].strftime('%Y-%m-%d')\n",
    "        location_days.append(data)\n",
    "\n",
    "    filename = f\"{location_id}.json\"\n",
    "    file_path = os.path.join(location_case_data, filename)\n",
    "\n",
    "    with open(file_path, 'w') as fo:\n",
    "        json.dump(location_days, fo, indent=4)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(f\"Uploading {location_id} {i} of {groups}\")\n",
    "    i += 1\n",
    "\n",
    "    s3_url = upload_file_to_s3(s3_bucket, file_path, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations_df.head(25)\n",
    "# locations_df = locations_df.reset_index()\n",
    "# locations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>cloud_resource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td></td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>https://thecodinginterface-covid.s3.amazonaws....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>albania</td>\n",
       "      <td></td>\n",
       "      <td>Albania</td>\n",
       "      <td>https://thecodinginterface-covid.s3.amazonaws....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>algeria</td>\n",
       "      <td></td>\n",
       "      <td>Algeria</td>\n",
       "      <td>https://thecodinginterface-covid.s3.amazonaws....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andorra</td>\n",
       "      <td></td>\n",
       "      <td>Andorra</td>\n",
       "      <td>https://thecodinginterface-covid.s3.amazonaws....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angola</td>\n",
       "      <td></td>\n",
       "      <td>Angola</td>\n",
       "      <td>https://thecodinginterface-covid.s3.amazonaws....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location_id province_state country_region  \\\n",
       "0  afghanistan                   Afghanistan   \n",
       "1      albania                       Albania   \n",
       "1      algeria                       Algeria   \n",
       "2      andorra                       Andorra   \n",
       "4       angola                        Angola   \n",
       "\n",
       "                                      cloud_resource  \n",
       "0  https://thecodinginterface-covid.s3.amazonaws....  \n",
       "1  https://thecodinginterface-covid.s3.amazonaws....  \n",
       "1  https://thecodinginterface-covid.s3.amazonaws....  \n",
       "2  https://thecodinginterface-covid.s3.amazonaws....  \n",
       "4  https://thecodinginterface-covid.s3.amazonaws....  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_df = daily_df[['location_id', 'province_state', 'country_region']].drop_duplicates()\n",
    "locations_df['cloud_resource'] = [cloud_resource_url(location_id, bucket_name) \n",
    "                                  for location_id in locations_df.location_id.values]\n",
    "locations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>cloud_resource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>us-nebraska</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>US</td>\n",
       "      <td>https://thecodinginterface-covid.s3.amazonaws....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     location_id province_state country_region  \\\n",
       "185  us-nebraska       Nebraska             US   \n",
       "\n",
       "                                        cloud_resource  \n",
       "185  https://thecodinginterface-covid.s3.amazonaws....  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_df[locations_df.province_state == 'Nebraska']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of dicts in the form:\n",
    "# [ \n",
    "#   {\n",
    "#     country_region: str,\n",
    "#     province_state: str,\n",
    "#     lat: float,\n",
    "#     long: float,\n",
    "#     filename: str,\n",
    "#     cloud_resource: str\n",
    "#   },\n",
    "#    ...\n",
    "# ]\n",
    "locations = []\n",
    "location_groups = locations_df.groupby(['location_id'])\n",
    "for k, location_data in location_groups:\n",
    "    for i, row in location_data.iterrows():\n",
    "        data = row.to_dict()\n",
    "        locations.append(data)\n",
    "        if i < 5:\n",
    "            print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize locations to JSON file\n",
    "with open('locations.json', 'w') as fo:\n",
    "    json.dump(locations, fo, indent=4)\n",
    "\n",
    "#!head -n 15 locations.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country / Region Dashboard\n",
    "\n",
    "Give user ability to select (aka drill down) into country, region, state, province\n",
    "\n",
    "Show confirmed, deaths, recovered\n",
    "\n",
    "Show time series of total confirmed\n",
    "\n",
    "Show time series of total recovered\n",
    "\n",
    "Show time series of total deaths\n",
    "\n",
    "Show time series of daily new confirmed\n",
    "\n",
    "Show time series of daily new recovered\n",
    "\n",
    "Show time series of daily new deaths\n",
    "\n",
    "Would be interesting to give a Gauge chart next to the daily graphs with an indicator of direction of n day movement (ie, over the last three days is new daily cases (deaths, confirmed, recovered) increasing, descreasing, maintaining)\n",
    "\n",
    "\n",
    "## Location Comparisons\n",
    "\n",
    "### Barcharts\n",
    "\n",
    "Death Rates: select locations to include and date in time (includes checkbox to make percent of population)\n",
    "\n",
    "Confirmed Counts: select locations to include and date in time (includes checkbox to make percent of population)\n",
    "\n",
    "\n",
    "### Line Charts\n",
    "\n",
    "Total Confirmed Cases: select locations to include and plot progression of cases since first case (includes checkbox to make percent of population)\n",
    "\n",
    "New Daily Confirmed Cases: select locations to include and plot progression of new cases since first case in each location (includes checkbox to make percent of population)\n",
    "\n",
    "Total Deaths: select locations to include and plot progression of deaths since first case (includes checkbox to make percent of population)\n",
    "\n",
    "New Daily Deaths: select locations to include and plot progression of deaths since first  case in each location (includes checkbox to make percent of population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df.to_csv('locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
